{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic_Music_Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic Music Generation"
      ],
      "metadata": {
        "id": "rmTY-MLHSjo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries"
      ],
      "metadata": {
        "id": "AIR-_kdASuBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from music21 import *\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "import keras.backend as K\n",
        "import random\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "aAeiPODbSsxa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the MIDI files"
      ],
      "metadata": {
        "id": "-z0_FD2uTYj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_midi(file):\n",
        "    \n",
        "    print(\"Loading Music File:\",file)\n",
        "    \n",
        "    notes=[]\n",
        "    notes_to_parse = None\n",
        "    \n",
        "    #parsing a midi file\n",
        "    midi = converter.parse(file)\n",
        "  \n",
        "    #grouping based on different instruments\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    #Looping over all the instruments\n",
        "    for part in s2.parts:\n",
        "    \n",
        "        #select elements of only piano\n",
        "        if 'Piano' in str(part): \n",
        "          notes_to_parse = part.recurse() \n",
        "          #finding whether a particular element is note or a chord\n",
        "          for element in notes_to_parse:\n",
        "            if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                \n",
        "                #chord\n",
        "            elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "\n",
        "    return np.array(notes)"
      ],
      "metadata": {
        "id": "kBuGKUqYTXQu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#specify the path\n",
        "path='/'\n",
        "\n",
        "#read all the filenames\n",
        "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
        "\n",
        "#reading each midi file\n",
        "notes_array = np.array([read_midi(path+i) for i in files])\n"
      ],
      "metadata": {
        "id": "ciaDLr4UT0hc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4565dcda-75c3-4df4-b902-0b30b5b06fc8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Music File: /midi_songs_Cids.mid\n",
            "Loading Music File: /midi_songs_traitor.mid\n",
            "Loading Music File: /midi_songs_Ff4-BattleLust.mid\n",
            "Loading Music File: /midi_songs_ultros.mid\n",
            "Loading Music File: /midi_songs_Final_Fantasy_7_-_Judgement_Day_Piano.mid\n",
            "Loading Music File: /midi_songs_ff4-town.mid\n",
            "Loading Music File: /midi_songs_Final_Fantasy_Matouyas_Cave_Piano.mid\n",
            "Loading Music File: /midi_songs_Gold_Silver_Rival_Battle.mid\n",
            "Loading Music File: /midi_songs_In_Zanarkand.mid\n",
            "Loading Music File: /midi_songs_Life_Stream.mid\n",
            "Loading Music File: /midi_songs_goldsaucer.mid\n",
            "Loading Music File: /midi_songs_Rydia_pc.mid\n",
            "Loading Music File: /midi_songs_FF3_Battle_(Piano).mid\n",
            "Loading Music File: /midi_songs_FFIII_Edgar_And_Sabin_Piano.mid\n",
            "Loading Music File: /midi_songs_thenightmarebegins.mid\n",
            "Loading Music File: /midi_songs_tifap.mid\n",
            "Loading Music File: /midi_songs_FF4.mid\n",
            "Loading Music File: /midi_songs_FF3_Third_Phase_Final_(Piano).mid\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the data"
      ],
      "metadata": {
        "id": "TKexHyY6UtmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting 2D array into 1D array\n",
        "notes_ = [element for note_ in notes_array for element in note_]\n",
        "\n",
        "#No. of unique notes\n",
        "unique_notes = list(set(notes_))\n",
        "print(len(unique_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ix4a5h3Us0Y",
        "outputId": "3d7a3bc7-6431-4771-df36-5eb85d6fe8a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the distribution of notes"
      ],
      "metadata": {
        "id": "5XWFzLtH_ieG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#computing frequency of each note\n",
        "freq = dict(Counter(notes_))\n",
        "\n",
        "#consider only the frequencies\n",
        "no=[count for _,count in freq.items()]\n",
        "\n",
        "#set the figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "#plot\n",
        "plt.hist(no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "1v423YmjbBCI",
        "outputId": "1e7493c5-6ac3-4c4b-9af6-34828594e455"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([166.,  13.,   9.,   9.,  14.,  10.,   3.,   1.,   0.,   2.]),\n",
              " array([  1. ,  42.7,  84.4, 126.1, 167.8, 209.5, 251.2, 292.9, 334.6,\n",
              "        376.3, 418. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn8AAAJdCAYAAABDKhHGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7hmZX0f/O8vTARBHdSYYGMawIpQbWJAY4EEEFuLZxrHV95cGmI8RCtQOZjkVTQ00ZRUPIKVlkTHhLRQ8UWLQTQJEAjYWAcN6SVyEMYEBZXTIEcF7/6x1g472733HNh7P/Ps+/O5rnXd89yH9dzPrJk937nXs9aq1loAAOjDj0x6AgAArBzhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjqyZ9AS2F1V1Q5LHJNk44akAAGzO7knubK3tsbUDhb+HPOaRj3zk4/bZZ5/HTXoiAACLueqqq3Lvvfdu01jh7yEb99lnn8dt2LBh0vMAAFjUfvvtlyuuuGLjtoz1nT8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBH1kx6Ar3Z/bf+dNJTWDIbT37hpKcAAGwlK38AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRkScJfVa2rqlOr6tKqurOqWlWduZkxO1TVa6vqkqq6varurarrq+rsqtprgTFHVtUXququqtpUVRdX1YuW4jMAAPRgzRLt58QkP5vkriQ3Jtl7sc5V9agkn0pyaJIvJ/lYkvuS/GSSX0yyV5Jr5ow5Jcnx4/7PSPKIJEckOa+qjm6tnbZEnwUAYNVaqvB3bIZQdl2Sg5NctJn+/yVD8HtDa+2/zG2sqh+d8/qADMHva0me1Vq7fax/d5INSU6pqk+31jY+zM8BALCqLclp39baRa21a1trbXN9q2rfJL+c5Oz5gt+4v+/PqXrDWL5rJviN/TYm+VCSHZO8elvmDgDQk0lc8PHLY/nfq2ptVb2yqv6/qnp9Vf2zBcYcOpYXzNP2mTl9AABYwFKd9t0azxrLn85wGvfxs9paVX04yTGttQeTpKp2yfBdwLtaazfNs79rx3Lei0QAAHjIJMLfj4/le5N8MsPFIjcmeXaS05P8uyTfSXLS2G/tWG5aYH8z9btuyZtX1YYFmha9SAUAYDWYxGnfmff8apJXtNa+2lq7q7X2F0nWJflBkuOq6hETmBsAwKo2iZW/O8byvJlTuzNaa39TVTckeXKSfZL8TR5a2Vub+c3U37FA+z/SWttvvvpxRXDfLdkHAMC0msTK39VjuVBYm7ma95FJ0lq7O8k3kjyqqp44T/+njOU187QBADDLJMLfn4/l0+c2VNWOeSjMbZzVdOFYHjbP/p4/pw8AAAuYRPj7RJJvJnlFVf38nLa3ZziNe1Fr7eZZ9aeP5duq6rEzlVW1e5I3Jbk/yUeXa8IAAKvFknznr6oOT3L4+HK3sdy/qtaPv76ltXZCMpzGrapfTfLpJJdW1f+f4bTus5P8QpJvJ/n12ftvrV1eVe9NclySK6vqnAyPd3tFksclOdrTPQAANm+pLvh4RpIj59TtOW5J8vUkJ8w0tNb+bFz1e3uSf5Vhte/mDCt8v9ta++bcN2itHV9Vf5thpe/1Ga4KviLJu1trn16izwEAsKotSfhrrZ2Uh+7Lt6Vj/ibDrV22Zsz6JOu3ZgwAAA+ZxHf+AACYEOEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6MiShL+qWldVp1bVpVV1Z1W1qjpzK8b/wTimVdU/W6DPDlV1bFVdWVX3VtVtVXV+VR2wFJ8BAKAHS7Xyd2KSo5I8I8k3tmZgVb04yWuS3LVIn0pyVpL3JnlEktOSnJvkoCSXVNVLt23aAAB9Warwd2ySvZI8Jskbt3RQVT0hyRlJzk6yYZGuRyRZl+TyJM9orb2ltfaaJM9J8mCSM6rq0ds4dwCAbixJ+GutXdRau7a11rZy6H8dyzdtpt9MoDyxtXbfrPf93xmC4xMyhEMAABYxsQs+qupXkxye5Ndba7cu0m+nJAckuSfJpfN0+cxYHrrUcwQAWG3WTOJNq+qnk3wgyZmttU9tpvuTk+yQ5PrW2gPztF87lntt4XsvdHp57y0ZDwAwzVZ85a+qfiTJxzJc4HHMFgxZO5abFmifqd/1YU4NAGDVm8TK37FJDk7ywtba7Sv95q21/earH1cE913h6QAArKgVXfmrqr2SvCvJR1tr52/hsJmVvbULtM/U3/Fw5gYA0IOVPu37z5PsmOTVs27q3KqqZVgNTJJrx7rDx9dfy3A7lz2rar6VyqeM5TXLOnMAgFVgpU/7bkzyhwu0vTDJbkk+nuTOsW9aa/dV1eVJfnHcLpoz7vljeeESzxUAYNVZ0fDXWvtyktfO11ZVF2cIf29trV03p/nDGYLfO6vquTP3+quqZyV5RZLvJPnEcs0bAGC1WJLwN56inTlNu9tY7l9V68df39JaO+FhvMVZSX4pw42cv1RV5yV5fIbgt0OS17XW7nwY+wcA6MJSrfw9I8mRc+r2HLck+XqSbQ5/rbVWVf9vhse7/VqSo5Pcl+SSJO9srV2+rfsGAOjJkoS/1tpJSU56mPs4ZDPtDyR537gBALANJvZ4NwAAVp7wBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6siThr6rWVdWpVXVpVd1ZVa2qzlyg71Oq6jer6sKq+vuq+l5VfauqPlVVz9nM+xxZVV+oqruqalNVXVxVL1qKzwAA0IOlWvk7MclRSZ6R5Bub6fu7SU5O8hNJzk/yniSXJXlhkgur6pj5BlXVKUnWJ3likjOSnJnkXyQ5r6qOevgfAQBg9VuzRPs5NsmNSa5LcnCSixbpe0GS32+tfWl2ZVUdnOTPkry7qj7eWrtpVtsBSY5P8rUkz2qt3T7WvzvJhiSnVNWnW2sbl+jzAACsSkuy8tdau6i1dm1rrW1B3/Vzg99Y/5dJLk7yiCQHzGl+w1i+ayb4jWM2JvlQkh2TvHrbZg8A0I/t7YKP74/lA3PqDx3LC+YZ85k5fQAAWMBSnfZ92Krqp5M8N8k9SS6ZVb9Lkp9MctfsU8GzXDuWe23h+2xYoGnvLZ8tAMB02i7CX1XtmORPMpy+/Y3Zp3aTrB3LTQsMn6nfdZmmBwCwakw8/FXVDkn+OMmBSc5Ocspyvl9rbb8F5rEhyb7L+d4AAJM20e/8jcHvzCQvT/I/krxynotGZlb21mZ+M/V3LP0MAQBWl4mFv6r60ST/PckRSf5bkl9urc290COttbsz3DvwUVX1xHl29ZSxvGa55goAsFpMJPxV1SOSfDzDit8fJXlVa+3BRYZcOJaHzdP2/Dl9AABYwIqHv/HijnOTvDTJHyZ5dWvtB5sZdvpYvq2qHjtrX7sneVOS+5N8dMknCwCwyizJBR9VdXiSw8eXu43l/lW1fvz1La21E8Zfn57kBUluyXA69x1VNXeXF7fWLp550Vq7vKrem+S4JFdW1TkZbgb9iiSPS3K0p3sAAGzeUl3t+4wkR86p23PckuTrSWbC3x5j+WNJ3rHIPi+e/aK1dnxV/W2Glb7XJ/lBkiuSvLu19ultnjkAQEeWJPy11k5KctIW9j3kYbzP+iTrt3U8AEDvtrfHuwEAsIyEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjSxL+qmpdVZ1aVZdW1Z1V1arqzM2MOaCqzq+q26rq3qq6sqreXFU7LDLmRVV1cVVtqqq7quqvq+rIpfgMAAA9WLNE+zkxyc8muSvJjUn2XqxzVb00ySeS3Jfk7CS3JXlxkvclOTDJy+cZc1SSU5PcmuTMJN9Lsi7J+qr6F621E5boswAArFpLddr32CR7JXlMkjcu1rGqHpPkjCQPJjmktfaa1tpbkjwjyeeTrKuqI+aM2T3JKRlC4jNba29qrR2b5GeSfC3J8VW1/xJ9FgCAVWtJwl9r7aLW2rWttbYF3dcleUKSs1prX5y1j/syrCAmPxwgfy3JjklOa61tnDXm9iS/N758wzZOHwCgG5O44OPQsbxgnrZLktyT5ICq2nELx3xmTh8AABawVN/52xpPHctr5ja01h6oqhuSPC3Jnkmu2oIxN1XV3UmeVFU7t9buWezNq2rDAk2Lfk8RAGA1mMTK39qx3LRA+0z9rtswZu0C7QAAZDIrfxPVWttvvvpxRXDfFZ4OAMCKmsTK3+ZW6Wbq79iGMQutDAIAkMmEv6vHcq+5DVW1JskeSR5Icv0Wjnlikl2S3Li57/sBAPRuEuHvwrE8bJ62g5LsnOTy1tr9Wzjm+XP6AACwgEmEv3OS3JLkiKp65kxlVe2U5J3jyw/PGfPRJPcnOWq84fPMmMcmeev48vRlmi8AwKqxJBd8VNXhSQ4fX+42lvtX1frx17fMPH6ttXZnVb0uQwi8uKrOyvDkjpdkuKXLORke+fYPWms3VNVbknwwyRer6uw89Hi3JyV5T2vt80vxWQAAVrOlutr3GUmOnFO357glydeT/MOzd1trn6yqg5O8LcnLkuyU5LokxyX54HxPCmmtnVpVG8f9/EqGVcuvJDmxtfaxJfocAACr2pKEv9baSUlO2soxlyV5wVaOOS/JeVszBgCAh0ziO38AAEyI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOjLR8FdVL6yqz1XVjVV1b1VdX1Ufr6r9F+h/QFWdX1W3jf2vrKo3V9UOKz13AIBpNLHwV1W/n+TTSfZNckGSDyS5IslLk1xWVa+c0/+lSS5JclCSc5OcluQRSd6X5KyVmzkAwPRaM4k3rardkpyQ5FtJfqa19u1Zbc9JcmGS30ly5lj3mCRnJHkwySGttS+O9W8f+66rqiNaa0IgAMAiJrXy99Pje//17OCXJK21i5J8N8kTZlWvG1+fNRP8xr73JTlxfPnGZZ0xAMAqMKnwd22S7yX5+ar6sdkNVXVQkkcn+fNZ1YeO5QXz7OuSJPckOaCqdlyGuQIArBoTOe3bWrutqn4zyXuTfKWqPpnk1iRPTvKSJH+W5NdnDXnqWF4zz74eqKobkjwtyZ5JrlrsvatqwwJNe2/VhwAAmEITCX9J0lp7f1VtTPKRJK+b1XRdkvVzTgevHctNC+xupn7XJZ0kAMAqM8mrfX8jyTlJ1mdY8dslyX5Jrk/yJ1X1n5bjfVtr+823JfnqcrwfAMD2ZCLhr6oOSfL7Sf5na+241tr1rbV7WmtXJPm3Sb6R5Piq2nMcMrOyt/aH9/aP6u9YrjkDAKwGk1r5e9FYXjS3obV2T5IvZJjbz43VV4/lXnP7V9WaJHskeSDDqiEAAAuYVPibuSr3CQu0z9R/bywvHMvD5ul7UJKdk1zeWrt/aaYHALA6TSr8XTqWr6+qn5zdUFXPT3JgkvuSXD5Wn5PkliRHVNUzZ/XdKck7x5cfXtYZAwCsApO62vecDPfx+1dJrqqqc5PcnGSfDKeEK8lvtdZuTZLW2p1V9bpx3MVVdVaS2zLcFuapY/3ZK/4pAACmzKTu8/eDqnpBkjclOSLDRR47Zwh05yf5YGvtc3PGfLKqDk7ytiQvS7JThtvCHDf2byv4EQAAptIk7/P3/STvH7ctHXNZkhcs26QAAFa5id3nDwCAlSf8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOTDz8VdVzq+rcqrq5qu6vqm9W1Wer6gXz9D2gqs6vqtuq6t6qurKq3lxVO0xi7gAA02bNJN+8qv5TkrckuTHJ/0xyS5InJNkvySFJzp/V96VJPpHkviRnJ7ktyYuTvC/JgUlevoJTBwCYShMLf1X1ugzB72NJXt9a+96c9h+d9evHJDkjyYNJDmmtfXGsf3uSC5Osq6ojWmtnrdT8AQCm0URO+1bVjkneleTvMk/wS5LW2vdnvVyXYUXwrJngN/a5L8mJ48s3Lt+MAQBWh0mt/P3rDGHu/Ul+UFUvTPL0DKd0v9Ba+/yc/oeO5QXz7OuSJPckOaCqdmyt3b9McwYAmHqTCn/PGsv7knwpQ/D7B1V1SZJ1rbXvjFVPHctr5u6otfZAVd2Q5GlJ9kxy1WJvXFUbFmjae8umDgAwvSZ1te+Pj+VbkrQkv5jk0Ul+JsnnkhyU5OOz+q8dy00L7G+mftelnSYAwOoyqZW/mdD5QJKXtNY2jq//tqr+bZKrkxxcVfvPcwr4YWmt7Tdf/bgiuO9SvhcAwPZmUit/d4zll2YFvyRJa+2eJJ8dX/78WM6s7K3N/Gbq71igHQCATC78XT2WC4W128fykXP67zW3Y1WtSbJHhlXE65dqggAAq9Gkwt9fZPiu3z+vqvnmMHMByA1jeeFYHjZP34OS7Jzkclf6AgAsbiLhr7X29STnJfmnSf797Laqel6Sf5NhVXDm1i7nZHj6xxFV9cxZfXdK8s7x5YeXedoAAFNvko93e1OSn0vy3vE+f1/KcPr28AxP8nhta21TkrTW7hyfCHJOkour6qwMj3d7SYbbwJyT4ZFvAAAsYlKnfdNauzHDM3xPS/KUDCuAh2RYETywtfaJOf0/meTgDDd1flmSo5N8P8lxSY5orbUVmzwAwJSa5Mpfxps4Hz1uW9L/siQvWNZJAQCsYhNb+QMAYOUJfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHtpvwV1WvrKo2bq9doM+LquriqtpUVXdV1V9X1ZErPVcAgGm1XYS/qvqpJKcluWuRPkclOS/J05OcmeSMJP8kyfqqOmUl5gkAMO0mHv6qqpJ8NMmtSU5foM/uSU5JcluSZ7bW3tRaOzbJzyT5WpLjq2r/FZkwAMAUm3j4S3JMkkOTvDrJ3Qv0+bUkOyY5rbW2caaytXZ7kt8bX75hGecIALAqTDT8VdU+SU5O8oHW2iWLdD10LC+Yp+0zc/oAALCANZN646pak+SPk/xdkrdupvtTx/KauQ2ttZuq6u4kT6qqnVtr92zmfTcs0LT3ZuYAADD1Jhb+krwjyc8l+YXW2r2b6bt2LDct0L4pyS5jv0XDHwBAzyYS/qrq2RlW+97TWvv8Sr53a22/Bea0Icm+KzkXAICVtuLf+RtP9/5RhlO4b9/CYTMrfmsXaN/cyiAAAJnMBR+PSrJXkn2S3Dfrxs4tyW+Pfc4Y694/vr56LPeau7OqemKGU743bu77fgAAvZvEad/7k/zhAm37Zvge4F9lCHwzp4QvTHJgksNm1c14/qw+AAAsYsXD33hxx0KPbzspQ/j7WGvtD2Y1fTTJbyQ5qqo+OnOvv6p6bB66UnjeG0QDAPCQSV7tu8VaazdU1VuSfDDJF6vq7CTfS7IuyZMygQtHAACm0VSEvyRprZ1aVRuTnJDkVzJ8X/ErSU5srX1sknMDAJgW21X4a62dlOSkRdrPS3LeSs0HAGC12R6e7QsAwAoR/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBARyYS/qrq8VX12qo6t6quq6p7q2pTVf1VVb2mquadV1UdUFXnV9Vt45grq+rNVbXDSn8GAIBptGZC7/vyJB9OclOSi5L8XZKfSPJLSf4gyfOr6uWttTYzoKpemuQTSe5LcnaS25K8OMn7khw47hMAgEVMKvxdk+QlSf60tfaDmcqqemuSLyR5WYYg+Imx/jFJzkjyYJJDWmtfHOvfnuTCJOuq6ojW2lkr+ikAAKbMRE77ttYubK2dNzv4jfU3Jzl9fHnIrKZ1SZ6Q5KyZ4Df2vy/JiePLNy7fjAEAVoft8YKP74/lA7PqDh3LC+bpf0mSe5IcUFU7LufEAACm3aRO+86rqtYk+ZXx5eyg99SxvGbumNbaA1V1Q5KnJdkzyVWbeY8NCzTtvXWzBQCYPtvbyt/JSZ6e5PzW2mdn1a8dy00LjJup33W5JgYAsBpsNyt/VXVMkuOTfDXJq5brfVpr+y3w/huS7Ltc7wsAsD3YLlb+quqoJB9I8pUkz2mt3Tany8zK3trMb6b+jmWYHgDAqjHx8FdVb05yapL/kyH43TxPt6vHcq95xq9JskeGC0SuX655AgCsBhMNf1X1mxlu0vzlDMHv2wt0vXAsD5un7aAkOye5vLV2/9LPEgBg9ZhY+Btv0Hxykg1Jnttau2WR7uckuSXJEVX1zFn72CnJO8eXH16uuQIArBYTueCjqo5M8jsZnthxaZJjqmput42ttfVJ0lq7s6pelyEEXlxVZ2V4vNtLMtwG5pwMj3wDAGARk7rad4+x3CHJmxfo85dJ1s+8aK19sqoOTvK2DI9/2ynJdUmOS/LB2c8BBgBgfhMJf621k5KctA3jLkvygqWeDwBALyZ+tS8AACtH+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoyKSe7QuwqN1/608nPYUls/HkF056CgD/wMofAEBHhD8AgI447cs2c1oOAKaPlT8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEfc5BlgmbkhOrA9sfIHANAR4Q8AoCPCHwBAR3znD7K6vpMFAIux8gcA0BHhDwCgI8IfAEBHhD8AgI4IfwAAHRH+AAA6IvwBAHRE+AMA6IjwBwDQEeEPAKAjwh8AQEeEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANCRNZOeAADTY/ff+tNJT2FJbDz5hZOeAkyMlT8AgI4IfwAAHXHaFwDYLqyWrxUk2/dXC6Zq5a+qnlRVH6mqb1bV/VW1sareX1WPnfTcAACmwdSs/FXVk5NcnuTHk3wqyVeT/HySf5/ksKo6sLV26wSnCACw3Zua8JfkP2cIfse01k6dqayq9yY5Nsm7krxhQnMDYIo4vUjPpuK077jq97wkG5N8aE7zbye5O8mrqmqXFZ4aAMBUmYrwl+Q5Y/m51toPZje01r6b5LIkOyf5lys9Md8FvsMAAAiSSURBVACAaTItp32fOpbXLNB+bYaVwb2S/MViO6qqDQs0/exVV12V/fbbb9tmuIVu+samZd0/AH3Z78/eMekpLJnV9G/kch+Xq666Kkl235ax0xL+1o7lQn8qZup3fRjv8eC999676Yorrtj4MPaxmL3H8qvLtH+2D47z6ucY92FqjvMV35r0DKbash3nFTguuye5c1sGTkv4WzKtteVd2lvAzIrjpN6fleE4r36OcR8c5z70epyn5Tt/Myt7axdon6m/YwXmAgAwtaYl/F09lnst0P6UsVzoO4EAAGR6wt9FY/m8qvpHc66qRyc5MMk9Sf7XSk8MAGCaTEX4a619LcnnMny58U1zmv9Dkl2S/HFr7e4VnhoAwFSZpgs+/l2Gx7t9sKqem+SqJM/OcA/Aa5K8bYJzAwCYCtVam/QctlhV/VSS30lyWJLHJ7kpyblJ/kNr7fZJzg0AYBpMVfgDAODhmYrv/AEAsDSEPwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPC3zKrqSVX1kar6ZlXdX1Ubq+r9VfXYSc+NH1ZV66rq1Kq6tKrurKpWVWduZswBVXV+Vd1WVfdW1ZVV9eaq2mGRMS+qqouralNV3VVVf11VRy79J2Kuqnp8Vb22qs6tquvGY7apqv6qql4z9xGSs8Y5zlOkqn6/qv6iqv5+PF63VdWXquq3q+rxC4xxjKdcVb1y/Lndquq1C/TZ6mNWVUdW1RfG/pvG8S9ank+xAlprtmXakjw5ybeStCSfTHJykgvH119N8vhJz9H2Q8fsy+Px+W6Gp8i0JGcu0v+lSR5IcleSP0zy7vHYtiQfX2DMUWP7LUk+lOR9Sf5+rDtl0r8Hq31L8obx9/qbSf4kyX9M8pEkd4z152S8B6rjPL1bku9leN77R8afvacm+d/j7/83kvyUY7y6tiQ/Nf49/u54DF67FMcsySlj+9+P/T+U5Nax7qhJf+5t+r2a9ARW85bks+MfjqPn1L93rD990nO0/dAxe06SpySpJIcsFv6SPCbJt5Pcn+SZs+p3yvAowpbkiDljdk9y3/iDY/dZ9Y9Nct04Zv9J/z6s5i3JoUlenORH5tTvluTvxmPwMsd5urckOy1Q/67x9/8/O8arZxt/Zv95kq9lCO4/FP625ZglOWCsvy7JY+fs69Zxf7sv1+dars1p32VSVU9O8rwkGzP8L2G2305yd5JXVdUuKzw1FtFau6i1dm0b/3ZvxrokT0hyVmvti7P2cV+SE8eXb5wz5teS7JjktNbaxlljbk/ye+PLN2zj9NkCrbULW2vntdZ+MKf+5iSnjy8PmdXkOE+h8fjM53+M5VNm1TnG0++YDP+xe3WGf1/nsy3HbOb1u9qsx8iO4z807u/VD3PuK074Wz7PGcvPzfOPzHeTXJZk5yT/cqUnxpI5dCwvmKftkiT3JDmgqnbcwjGfmdOHlff9sXxgVp3jvLq8eCyvnFXnGE+xqtonw6n9D7TWLlmk67Ycs1V5nIW/5fPUsbxmgfZrx3KvFZgLy2PBY9xaeyDJDUnWJNlzC8fclOF/rE+qqp2XdqpsTlWtSfIr48vZP+gd5ylWVSdU1UlV9b6qujTJ72YIfifP6uYYT6nx7+0fZ/jKxls3032rjtl4Zu4nk9w1ts81tf+Or5n0BFaxtWO5aYH2mfpdV2AuLI9tOcZbMmaXsd89D2t2bK2Tkzw9yfmttc/Oqnecp9sJSX5i1usLkvxqa+07s+oc4+n1jiQ/l+QXWmv3bqbv1h6zVfvvuJU/oHtVdUyS4zNc3fmqCU+HJdRa2621Vhku6PmlDKt3X6qqfSc7Mx6uqnp2htW+97TWPj/p+UwT4W/5zPyPYO0C7TP1d6zAXFge23KMt3TMQv/TZIlV1VFJPpDkK0me01q7bU4Xx3kVaK19q7V2boYL8R6f5I9mNTvGU2Y83ftHGU7hvn0Lh23tMVu1/44Lf8vn6rFc6LsAM1eaLfSdQLZ/Cx7j8QfTHhkuHLh+C8c8McMphxtba04TrYCqenOG+7/9nwzB7+Z5ujnOq0hr7esZgv7TqurHxmrHePo8KsPv/T5J7pt1Y+eW4Y4aSXLGWPf+8fVWHbPW2t0Z7gn5qLF9rqn9d1z4Wz4XjeXz5j4xoKoeneTADN8p+F8rPTGWzIVjedg8bQdluJr78tba/Vs45vlz+rCMquo3M9yw9csZgt+3F+jqOK8+/2QsHxxLx3j63J/hZtzzbV8a+/zV+HrmlPC2HLPVeZwnfaPB1bzFTZ6nesuW3eT5O9m6G8PuETeGnfiW4TRRS/LFJI/bTF/Hecq2DCs7a+ep/5E8dJPnyxzj1bklOSnz3+R5q49ZVulNnmv8ECyD8UbPlyf58SSfyvC4sGdnuAfgNUkOaK3dOrkZMldVHZ7k8PHlbkn+TYZTPZeOdbe01k6Y0/+cDD8AzkpyW5KXZLilwDlJ/p825y9ZVR2d5IMZfnCcneExVOuSPCnDF5dPCMtmfIbn+gyrPqdm/u9kbWytrZ81xnGeIuPp/P+YYeXnhgzH4CeSHJzhgo+bkzy3tfaVWWMc41Wiqk7KcOr3da21P5jTttXHrKrek+S4JDdm+LPwiCSvyPDd0aNba6ct24dZLpNOn6t9y/CswY8muSnDH7KvJ3l/Zv0Pwrb9bHnof4wLbRvnGXNgkvOT3J7k3iR/m+TYJDss8j4vTvKXGZ5BeXeGZ44eOenP38O2Bce4JbnYcZ7eLcMte07LcEr/lgzf19s0/v6flAVWex3j1bFlgZW/h3PMkvzq2O/ucdxfJnnRpD/rtm5W/gAAOuKCDwCAjgh/AAAdEf4AADoi/AEAdET4AwDoiPAHANAR4Q8AoCPCHwBAR4Q/AICOCH8AAB0R/gAAOiL8AQB0RPgDAOiI8AcA0BHhDwCgI8IfAEBHhD8AgI78X9sUQGXio43jAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 319,
              "height": 302
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there are a lot of low frequency notes we remove them using the condition frequency > 50. It can be changed as per required."
      ],
      "metadata": {
        "id": "rmYK8aMqBEub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
        "print(len(frequent_notes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeM79h-MbRwp",
        "outputId": "e8aa07ea-b49f-49fa-89d6-2a2a22d37e12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# New file with filtered notes\n",
        "new_music=[]\n",
        "\n",
        "for notes in notes_array:\n",
        "    temp=[]\n",
        "    for note_ in notes:\n",
        "        if note_ in frequent_notes:\n",
        "            temp.append(note_)            \n",
        "    new_music.append(temp)\n",
        "    \n",
        "new_music = np.array(new_music)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmV9JXVqbbs3",
        "outputId": "ca5a6394-9c73-4a5b-fd42-f92b18ee0db8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing the data"
      ],
      "metadata": {
        "id": "sszselBJbgCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_of_timesteps = 32\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for note_ in new_music:\n",
        "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
        "        \n",
        "        #preparing input and output sequences\n",
        "        input_ = note_[i:i + no_of_timesteps]\n",
        "        output = note_[i + no_of_timesteps]\n",
        "        \n",
        "        x.append(input_)\n",
        "        y.append(output)\n",
        "        \n",
        "x=np.array(x)\n",
        "y=np.array(y)"
      ],
      "metadata": {
        "id": "kipGZCj1biNz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_x = list(set(x.ravel()))\n",
        "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
      ],
      "metadata": {
        "id": "TVZHa1Vcbp3b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing input sequences\n",
        "x_seq=[]\n",
        "for i in x:\n",
        "    temp=[]\n",
        "    for j in i:\n",
        "        #assigning unique integer to every note\n",
        "        temp.append(x_note_to_int[j])\n",
        "    x_seq.append(temp)\n",
        "    \n",
        "x_seq = np.array(x_seq)"
      ],
      "metadata": {
        "id": "nD5dzVh0buls"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_y = list(set(y))\n",
        "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
        "y_seq=np.array([y_note_to_int[i] for i in y])"
      ],
      "metadata": {
        "id": "UpYC8dvlbyEs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split - 80/20"
      ],
      "metadata": {
        "id": "9pNvtTLNFhKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "FAiEKakjb10z"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Building"
      ],
      "metadata": {
        "id": "DhlH1p4fb8mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model following Wavenet architecture"
      ],
      "metadata": {
        "id": "PTY_-4X0Gosz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "model = Sequential()\n",
        "    \n",
        "#embedding layer\n",
        "model.add(Embedding(len(unique_x), 100, input_length=32,trainable=True)) \n",
        "\n",
        "model.add(Conv1D(64,3, padding='causal',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "    \n",
        "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "\n",
        "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPool1D(2))\n",
        "          \n",
        "#model.add(Conv1D(256,5,activation='relu'))    \n",
        "model.add(GlobalMaxPool1D())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(unique_y), activation='softmax'))\n",
        "    \n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKHNzEe3cCxF",
        "outputId": "82ba0e79-97f6-499a-f740-5b8a7fbd4dbc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 32, 100)           5600      \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 32, 64)            19264     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 32, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 16, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 16, 128)           24704     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 8, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 8, 256)            98560     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 8, 256)            0         \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 4, 256)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 56)                14392     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 228,312\n",
            "Trainable params: 228,312\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving only the best model using callback\n",
        "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
      ],
      "metadata": {
        "id": "uVLDfgoZcKWy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model with 50 epochs and batch size 128\n",
        "history = model.fit(np.array(x_tr),np.array(y_tr),batch_size=128,\n",
        "                    epochs=50, validation_data=(np.array(x_val),np.array(y_val)),verbose=1, callbacks=[mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBnF7TtVcOdp",
        "outputId": "5dffc275-a4dc-48a7-eb6f-0c067150a804"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 3.8874\n",
            "Epoch 00001: val_loss improved from inf to 3.78083, saving model to best_model.h5\n",
            "57/57 [==============================] - 11s 149ms/step - loss: 3.8870 - val_loss: 3.7808\n",
            "Epoch 2/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 3.6225\n",
            "Epoch 00002: val_loss improved from 3.78083 to 3.52027, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 3.6220 - val_loss: 3.5203\n",
            "Epoch 3/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 3.3494\n",
            "Epoch 00003: val_loss improved from 3.52027 to 3.36373, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 3.3482 - val_loss: 3.3637\n",
            "Epoch 4/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 3.1874\n",
            "Epoch 00004: val_loss improved from 3.36373 to 3.27956, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 3.1857 - val_loss: 3.2796\n",
            "Epoch 5/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 3.0645\n",
            "Epoch 00005: val_loss improved from 3.27956 to 3.17647, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 3.0636 - val_loss: 3.1765\n",
            "Epoch 6/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.9808\n",
            "Epoch 00006: val_loss improved from 3.17647 to 3.11243, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.9801 - val_loss: 3.1124\n",
            "Epoch 7/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.8983\n",
            "Epoch 00007: val_loss improved from 3.11243 to 3.04380, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.8994 - val_loss: 3.0438\n",
            "Epoch 8/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.8381\n",
            "Epoch 00008: val_loss improved from 3.04380 to 3.02136, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.8378 - val_loss: 3.0214\n",
            "Epoch 9/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.7710\n",
            "Epoch 00009: val_loss improved from 3.02136 to 2.95408, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.7711 - val_loss: 2.9541\n",
            "Epoch 10/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.7011\n",
            "Epoch 00010: val_loss improved from 2.95408 to 2.93668, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.7026 - val_loss: 2.9367\n",
            "Epoch 11/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.6577\n",
            "Epoch 00011: val_loss improved from 2.93668 to 2.86442, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.6584 - val_loss: 2.8644\n",
            "Epoch 12/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.5940\n",
            "Epoch 00012: val_loss improved from 2.86442 to 2.86123, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.5937 - val_loss: 2.8612\n",
            "Epoch 13/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.5463\n",
            "Epoch 00013: val_loss improved from 2.86123 to 2.79378, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.5486 - val_loss: 2.7938\n",
            "Epoch 14/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.5003\n",
            "Epoch 00014: val_loss did not improve from 2.79378\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.5007 - val_loss: 2.7951\n",
            "Epoch 15/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.4507\n",
            "Epoch 00015: val_loss improved from 2.79378 to 2.75043, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.4497 - val_loss: 2.7504\n",
            "Epoch 16/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.3894\n",
            "Epoch 00016: val_loss improved from 2.75043 to 2.69791, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.3886 - val_loss: 2.6979\n",
            "Epoch 17/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.3549\n",
            "Epoch 00017: val_loss improved from 2.69791 to 2.67823, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.3556 - val_loss: 2.6782\n",
            "Epoch 18/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.2941\n",
            "Epoch 00018: val_loss improved from 2.67823 to 2.63453, saving model to best_model.h5\n",
            "57/57 [==============================] - 7s 116ms/step - loss: 2.2940 - val_loss: 2.6345\n",
            "Epoch 19/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.2473\n",
            "Epoch 00019: val_loss improved from 2.63453 to 2.60968, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 88ms/step - loss: 2.2466 - val_loss: 2.6097\n",
            "Epoch 20/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.2019\n",
            "Epoch 00020: val_loss improved from 2.60968 to 2.56138, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 88ms/step - loss: 2.2026 - val_loss: 2.5614\n",
            "Epoch 21/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.1528\n",
            "Epoch 00021: val_loss improved from 2.56138 to 2.55593, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.1520 - val_loss: 2.5559\n",
            "Epoch 22/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.1255\n",
            "Epoch 00022: val_loss improved from 2.55593 to 2.50209, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 2.1267 - val_loss: 2.5021\n",
            "Epoch 23/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.0690\n",
            "Epoch 00023: val_loss improved from 2.50209 to 2.45267, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.0689 - val_loss: 2.4527\n",
            "Epoch 24/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 2.0413\n",
            "Epoch 00024: val_loss improved from 2.45267 to 2.43329, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 2.0421 - val_loss: 2.4333\n",
            "Epoch 25/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.9745\n",
            "Epoch 00025: val_loss did not improve from 2.43329\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.9743 - val_loss: 2.4438\n",
            "Epoch 26/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.9407\n",
            "Epoch 00026: val_loss improved from 2.43329 to 2.41623, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.9404 - val_loss: 2.4162\n",
            "Epoch 27/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.8971\n",
            "Epoch 00027: val_loss improved from 2.41623 to 2.35732, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 88ms/step - loss: 1.8985 - val_loss: 2.3573\n",
            "Epoch 28/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.8702\n",
            "Epoch 00028: val_loss improved from 2.35732 to 2.34682, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.8696 - val_loss: 2.3468\n",
            "Epoch 29/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.8220\n",
            "Epoch 00029: val_loss improved from 2.34682 to 2.31264, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.8224 - val_loss: 2.3126\n",
            "Epoch 30/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.7856\n",
            "Epoch 00030: val_loss did not improve from 2.31264\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.7869 - val_loss: 2.3242\n",
            "Epoch 31/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.7590\n",
            "Epoch 00031: val_loss improved from 2.31264 to 2.26975, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 89ms/step - loss: 1.7594 - val_loss: 2.2698\n",
            "Epoch 32/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.7175\n",
            "Epoch 00032: val_loss improved from 2.26975 to 2.22911, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 89ms/step - loss: 1.7181 - val_loss: 2.2291\n",
            "Epoch 33/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.6840\n",
            "Epoch 00033: val_loss did not improve from 2.22911\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.6848 - val_loss: 2.2465\n",
            "Epoch 34/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.6499\n",
            "Epoch 00034: val_loss improved from 2.22911 to 2.20509, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 89ms/step - loss: 1.6512 - val_loss: 2.2051\n",
            "Epoch 35/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.6253\n",
            "Epoch 00035: val_loss improved from 2.20509 to 2.20325, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.6243 - val_loss: 2.2032\n",
            "Epoch 36/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.5917\n",
            "Epoch 00036: val_loss improved from 2.20325 to 2.18149, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 1.5921 - val_loss: 2.1815\n",
            "Epoch 37/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.5587\n",
            "Epoch 00037: val_loss improved from 2.18149 to 2.15409, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.5591 - val_loss: 2.1541\n",
            "Epoch 38/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.5350\n",
            "Epoch 00038: val_loss improved from 2.15409 to 2.13904, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 1.5362 - val_loss: 2.1390\n",
            "Epoch 39/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.5157\n",
            "Epoch 00039: val_loss improved from 2.13904 to 2.10580, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 1.5145 - val_loss: 2.1058\n",
            "Epoch 40/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.4972\n",
            "Epoch 00040: val_loss did not improve from 2.10580\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.4970 - val_loss: 2.1156\n",
            "Epoch 41/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.4494\n",
            "Epoch 00041: val_loss improved from 2.10580 to 2.10322, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.4485 - val_loss: 2.1032\n",
            "Epoch 42/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.4381\n",
            "Epoch 00042: val_loss improved from 2.10322 to 2.06989, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.4378 - val_loss: 2.0699\n",
            "Epoch 43/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.4157\n",
            "Epoch 00043: val_loss improved from 2.06989 to 2.06124, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.4149 - val_loss: 2.0612\n",
            "Epoch 44/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.3762\n",
            "Epoch 00044: val_loss improved from 2.06124 to 2.03634, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.3754 - val_loss: 2.0363\n",
            "Epoch 45/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.3595\n",
            "Epoch 00045: val_loss did not improve from 2.03634\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.3586 - val_loss: 2.0414\n",
            "Epoch 46/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.3341\n",
            "Epoch 00046: val_loss did not improve from 2.03634\n",
            "57/57 [==============================] - 5s 85ms/step - loss: 1.3322 - val_loss: 2.0486\n",
            "Epoch 47/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.3344\n",
            "Epoch 00047: val_loss improved from 2.03634 to 2.01611, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 88ms/step - loss: 1.3344 - val_loss: 2.0161\n",
            "Epoch 48/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.2976\n",
            "Epoch 00048: val_loss improved from 2.01611 to 1.99086, saving model to best_model.h5\n",
            "57/57 [==============================] - 5s 87ms/step - loss: 1.2978 - val_loss: 1.9909\n",
            "Epoch 49/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.2968\n",
            "Epoch 00049: val_loss did not improve from 1.99086\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.2967 - val_loss: 2.0184\n",
            "Epoch 50/50\n",
            "56/57 [============================>.] - ETA: 0s - loss: 1.2656\n",
            "Epoch 00050: val_loss did not improve from 1.99086\n",
            "57/57 [==============================] - 5s 86ms/step - loss: 1.2688 - val_loss: 1.9980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading best model\n",
        "model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "RdkZaibpdSrD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating own music using the model"
      ],
      "metadata": {
        "id": "lkgcMY7HHBXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ind = np.random.randint(0,len(x_val)-1)\n",
        "\n",
        "random_music = x_val[ind]\n",
        "\n",
        "predictions=[]\n",
        "for i in range(10):\n",
        "\n",
        "    random_music = random_music.reshape(1,no_of_timesteps)\n",
        "\n",
        "    prob  = model.predict(random_music)[0]\n",
        "    y_pred= np.argmax(prob,axis=0)\n",
        "    predictions.append(y_pred)\n",
        "\n",
        "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
        "    random_music = random_music[1:]\n",
        "    \n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJWWKCvsdngz",
        "outputId": "7afc4e91-aa95-4851-94d9-325c168d3f64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 48, 11, 2, 28, 6, 2, 48, 6, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting integers back to notes"
      ],
      "metadata": {
        "id": "6NSAKnRxHpSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
        "predicted_notes = [x_int_to_note[i] for i in predictions]"
      ],
      "metadata": {
        "id": "pM0GKzBodsvo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally converting the notes back to midi file and downloading the generated music"
      ],
      "metadata": {
        "id": "HNm4c7aBHtgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_midi(prediction_output):\n",
        "   \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        \n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                \n",
        "                cn=int(current_note)\n",
        "                new_note = note.Note(cn)\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "                \n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "            \n",
        "        # pattern is a note\n",
        "        else:\n",
        "            \n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 1\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    out_file = midi_stream.write('midi', fp='music.mid')\n",
        "    midi_stream.show('midi')"
      ],
      "metadata": {
        "id": "yRaKfJaAdzQh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_to_midi(predicted_notes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "z3NYglhKd33h",
        "outputId": "f594c091-2512-43ca-c09e-5adc3be6fae3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                <div id='midiPlayerDiv46873'></div>\n",
              "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
              "                    type=\"text/css\" />\n",
              "                <script>\n",
              "                require.config({\n",
              "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
              "                });\n",
              "                require(['music21'], function() {\n",
              "                               mp = new music21.miditools.MidiPlayer();\n",
              "                               mp.addPlayer('#midiPlayerDiv46873');\n",
              "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQABBABNVHJrAAAAZwD/AwAA4ABAAJA5WogAgDkAAJA7WogAgDsAAJBDWogAgEMAAJA5WogAgDkAAJA6WogAgDoAAJBBWogAgEEAAJA5WogAgDkAAJA7WogAgDsAAJBBWogAgEEAAJA5WogAgDkAiAD/LwA=');\n",
              "                        });\n",
              "                </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}